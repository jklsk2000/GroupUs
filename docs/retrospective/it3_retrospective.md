# Iteration 3 Retrospective
## What went well?
* The matchParticipant algorithm in the Recommender class has been implemented and we have demonstrated that it works
* The merging between different branches went better than the previous iteration through more communication this time around
* The front-end UI has significantly improved compared to the last iteration. The website now has reasonable functionalities. <br />

## Items Delivered:
* Back-end survey functionality.
* We now have input validation functionality for the survey creation prompt. <br />

## Front-end survey functionality.
* Instructors can now create and edit surveys.
* Create survey functionality now uses the new survey class.
* The instructor can specify the max number of questions per survey.
* The recommendation algorithm is done.
* Functionality for matching users given similarity scores
* The backend can support both questions where users being similar is good and questions where we want answers to be as different as possible (frontend supports where we want similar only)
* Front-end for the recommendation algorithm, we can make recommendations for which usernames belong in which team is visible on the frontend (this functionality is connected so we can get recommendations based on responses to a given survey) <br />

## Items Not Delivered: 
* Updating the group class and splitting it into group and event so our recommendation flow is more natural <br />

## What can we do better?
* Checking in more throughout the week 
* During iteration 3, it was hard for us to get together and update each other on the progress. From iteration 4, we decided to add a task sheet on our github with specific internal deadlines. Also, we are meeting in-person twice a week during OOSE lecture time to move forward on the tasks. 
